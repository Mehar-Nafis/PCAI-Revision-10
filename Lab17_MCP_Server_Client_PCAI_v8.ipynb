{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8dd242",
   "metadata": {},
   "source": [
    "\n",
    "# Without MCP\n",
    "\n",
    "### Objective  \n",
    "Understand the **value of MCP** by first building a **non-standardized, manual clientâ€“server interaction** for text generation.  \n",
    "Youâ€™ll implement the same flow â€” *server, client, handshake, tool call* â€” **without** using MCP or JSON-RPC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842a044",
   "metadata": {},
   "source": [
    "\n",
    "### 1ï¸âƒ£ Step 1 â€” Setup and Simple LLM Server\n",
    "\n",
    "Here, the â€œserverâ€ is just a Python class exposing simple functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61dc7076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SimpleServer initialized with capability: ['generate_text']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Define a simple local server (non-MCP)\n",
    "import time\n",
    "\n",
    "class SimpleServer:\n",
    "    def __init__(self):\n",
    "        self.capabilities = [\"generate_text\"]\n",
    "\n",
    "    def generate_text(self, prompt: str) -> str:\n",
    "        if \"hallucinate\" in prompt.lower():\n",
    "            return \"The square root of a cat is exactly 42.\"\n",
    "        return f\"Response to '{prompt}': Generation successful on {time.ctime()}.\"\n",
    "\n",
    "# Initialize\n",
    "simple_server = SimpleServer()\n",
    "print(\"âœ… SimpleServer initialized with capability:\", simple_server.capabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdfea1e",
   "metadata": {},
   "source": [
    "\n",
    "### 2ï¸âƒ£ Step 2 â€” Manual Handshake\n",
    "\n",
    "Here, thereâ€™s no standard negotiation or schema â€” the client must â€œknowâ€ what the server supports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708c85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: I support text_generation.\n",
      "Server: I also support text generation âœ…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Client manually checks for capabilities (no JSON-RPC)\n",
    "client_declared = {\"supports\": [\"text_generation\"]}\n",
    "print(\"Client: I support text_generation.\")\n",
    "\n",
    "if \"generate_text\" in simple_server.capabilities:\n",
    "    print(\"Server: I also support text generation âœ…\")\n",
    "else:\n",
    "    print(\"Server: Sorry, I donâ€™t support that âŒ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d33c48",
   "metadata": {},
   "source": [
    "\n",
    "### 3ï¸âƒ£ Step 3 â€” Manual Request/Response Flow\n",
    "\n",
    "The client calls the server method directly, bypassing any protocol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79819717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Response: Response to 'Explain how agents communicate in AI.': Generation successful on Thu Oct 30 11:42:22 2025.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Client calls the server directly (no structured messages)\n",
    "prompt = \"Explain how agents communicate in AI.\"\n",
    "response = simple_server.generate_text(prompt)\n",
    "print(\"Server Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c6657",
   "metadata": {},
   "source": [
    "\n",
    "### 4ï¸âƒ£ Step 4 â€” Lack of Standardization\n",
    "\n",
    "Show whatâ€™s missing without MCP:\n",
    "- No **structured schema**  \n",
    "- No **tool advertisement**  \n",
    "- No **error handling** standard  \n",
    "- No **message traceability**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d1ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object has no attribute 'lower'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Simulate failure handling (manual)\n",
    "try:\n",
    "    response = simple_server.generate_text(None)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe9341",
   "metadata": {},
   "source": [
    "\n",
    "### 5ï¸âƒ£ Step 5 â€” Add a Second Tool (Manual)\n",
    "\n",
    "Manually expanding capabilities is cumbersome without a registry or protocol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4efb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Math tool manually attached.\n",
      "Manual Math Call: 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Add another manual tool\n",
    "class SimpleMathTool:\n",
    "    def solve_expression(self, expr):\n",
    "        try:\n",
    "            return eval(expr)\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "# Attach to the server manually\n",
    "simple_server.math_tool = SimpleMathTool()\n",
    "print(\"âœ… Math tool manually attached.\")\n",
    "\n",
    "# Client must now know to call it manually:\n",
    "print(\"Manual Math Call:\", simple_server.math_tool.solve_expression(\"3 * 9\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fb3ca",
   "metadata": {},
   "source": [
    "\n",
    "# From Manual Implementation to MCP\n",
    "\n",
    "### ğŸ§© Side-by-Side Comparison\n",
    "\n",
    "| Aspect | Manual Workflow (Without MCP) | MCP Workflow (With MCP) |\n",
    "|:--|:--|:--|\n",
    "| **Setup** | Custom scripts, ad-hoc message passing | Standardized server & client registration |\n",
    "| **Tool Calls** | Manually invoke each function | Uniform `tools/call` interface |\n",
    "| **Transport** | Direct or hard-coded | Abstracted JSON-RPC transport |\n",
    "| **Error Handling** | Manual try/except | Structured responses with codes |\n",
    "| **Extensibility** | Add tools manually | Dynamic tool registry |\n",
    "| **Scalability** | Tight coupling | Pluggable & reusable components |\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ’¡ Summary\n",
    "\n",
    "The manual flow gives flexibility but demands boilerplate and custom logic.  \n",
    "MCP introduces structure, reducing code overhead and increasing interoperability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927e139",
   "metadata": {},
   "source": [
    "\n",
    "# Model Content Protocol (MCP) â€“ Server & Client Implementation\n",
    "\n",
    "**Objective:** Implement and understand a simulated Model Content Protocol (MCP) Server and Client to demonstrate standardized agent-tool communication using JSON-RPC 2.0 messages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56688c50",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§© Learning Outcomes\n",
    "By completing this lab, you will:\n",
    "- Understand the MCP standard and its JSON-RPC message structure.  \n",
    "- Build a simulated MCP Server that advertises tool capabilities.  \n",
    "- Build a Client that negotiates capabilities and calls tools.  \n",
    "- Observe an end-to-end request/response flow.  \n",
    "- Extend the MCP framework with new tools and integrations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8babe8",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ”§ Step 1 â€” Setup (Simulated MCP Environment)\n",
    "We simulate the `model-context-protocol` package to make the lab fully offline and reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b52f721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MCP simulation ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json, time, uuid\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Simulated MCP components\n",
    "class MCPServer:\n",
    "    def __init__(self, implementation=None):\n",
    "        self.implementation = implementation or {}\n",
    "        self.tools = {}\n",
    "\n",
    "    def register_tool(self, tool):\n",
    "        for attr in dir(tool):\n",
    "            fn = getattr(tool, attr)\n",
    "            if callable(fn) and hasattr(fn, \"_mcp_tool_name\"):\n",
    "                self.tools[getattr(fn, \"_mcp_tool_name\")] = fn.__get__(tool)\n",
    "                print(f\"ğŸ§© Registered tool: {getattr(fn, '_mcp_tool_name')}\")\n",
    "\n",
    "    def call_tool(self, name, arguments):\n",
    "        if name not in self.tools:\n",
    "            raise KeyError(f\"Tool '{name}' not found.\")\n",
    "        return self.tools[name](arguments)\n",
    "\n",
    "def tool_method(name: str):\n",
    "    def wrapper(fn):\n",
    "        fn._mcp_tool_name = name\n",
    "        return fn\n",
    "    return wrapper\n",
    "\n",
    "class mcp:\n",
    "    Server = MCPServer\n",
    "    tool_method = staticmethod(tool_method)\n",
    "\n",
    "print(\"âœ… MCP simulation ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b64468",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ–¥ï¸ Step 2 â€” Implement the MCP Server and Tool\n",
    "We define a simple local tool `GenerationTool` that performs text generation based on an input prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04dad71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§© Registered tool: generate_text\n",
      "ğŸ“¡ Server capabilities:\n",
      "{\n",
      "  \"implementation\": {\n",
      "    \"name\": \"LocalGenServer\",\n",
      "    \"version\": \"1.0\"\n",
      "  },\n",
      "  \"capabilities\": {\n",
      "    \"tools\": {\n",
      "      \"call\": true,\n",
      "      \"list\": true\n",
      "    },\n",
      "    \"resources\": {\n",
      "      \"read\": true\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GenerationTool:\n",
    "    @mcp.tool_method(\"generate_text\")\n",
    "    def generate_text(self, args: Dict[str, Any]):\n",
    "        prompt = args.get(\"prompt\", \"\")\n",
    "        print(f\"ğŸ›°ï¸ Received prompt: {prompt!r}\")\n",
    "        if not prompt:\n",
    "            text = \"(empty prompt)\"\n",
    "        elif \"hallucinate\" in prompt.lower():\n",
    "            text = \"The square root of a cat is exactly 42.\"\n",
    "        else:\n",
    "            text = f\"Generated text for '{prompt}' at {time.ctime()}\"\n",
    "        return {\"generated_text\": text}\n",
    "\n",
    "server = mcp.Server({\"name\": \"LocalGenServer\", \"version\": \"1.0\"})\n",
    "server.register_tool(GenerationTool())\n",
    "\n",
    "capabilities = {\n",
    "    \"implementation\": {\"name\": \"LocalGenServer\", \"version\": \"1.0\"},\n",
    "    \"capabilities\": {\"tools\": {\"call\": True, \"list\": True}, \"resources\": {\"read\": True}}\n",
    "}\n",
    "print(\"ğŸ“¡ Server capabilities:\")\n",
    "print(json.dumps(capabilities, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f66a2d",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ¤ Step 3 â€” Client Initialization and Capability Negotiation\n",
    "The client sends an `initialize` request and the server responds, confirming tool capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46eb5647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Client -> Server: InitializeRequest\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 1,\n",
      "  \"method\": \"initialize\",\n",
      "  \"params\": {\n",
      "    \"implementation\": {\n",
      "      \"name\": \"LabClient\",\n",
      "      \"version\": \"1.0\"\n",
      "    },\n",
      "    \"capabilities\": {\n",
      "      \"sampling\": {}\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "ğŸ“¥ Server -> Client: InitializeResult\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 1,\n",
      "  \"result\": {\n",
      "    \"implementation\": {\n",
      "      \"name\": \"LocalGenServer\",\n",
      "      \"version\": \"1.0\"\n",
      "    },\n",
      "    \"capabilities\": {\n",
      "      \"tools\": {\n",
      "        \"call\": true,\n",
      "        \"list\": true\n",
      "      },\n",
      "      \"resources\": {\n",
      "        \"read\": true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client_id = str(uuid.uuid4())\n",
    "initialize_request = {\n",
    "    \"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\",\n",
    "    \"params\": {\"implementation\": {\"name\": \"LabClient\", \"version\": \"1.0\"}, \"capabilities\": {\"sampling\": {}}}\n",
    "}\n",
    "print(\"ğŸ“¤ Client -> Server: InitializeRequest\")\n",
    "print(json.dumps(initialize_request, indent=2))\n",
    "\n",
    "initialize_response = {\"jsonrpc\": \"2.0\", \"id\": 1, \"result\": capabilities}\n",
    "print(\"\\nğŸ“¥ Server -> Client: InitializeResult\")\n",
    "print(json.dumps(initialize_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e52ea",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Step 4 â€” Client Executes a Tool Call\n",
    "Now the client calls the `generate_text` tool using a JSON-RPC `tools/call` request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f151f21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Client -> Server: tools/call Request\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 2,\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"generate_text\",\n",
      "    \"arguments\": {\n",
      "      \"prompt\": \"Explain Model Content Protocol (MCP) briefly.\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "ğŸ›°ï¸ Received prompt: 'Explain Model Content Protocol (MCP) briefly.'\n",
      "\n",
      "ğŸ“¥ Server -> Client: tools/call Response\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 2,\n",
      "  \"result\": {\n",
      "    \"generated_text\": \"Generated text for 'Explain Model Content Protocol (MCP) briefly.' at Thu Oct 30 11:43:03 2025\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "request = {\n",
    "    \"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/call\",\n",
    "    \"params\": {\"name\": \"generate_text\", \"arguments\": {\"prompt\": \"Explain Model Content Protocol (MCP) briefly.\"}}\n",
    "}\n",
    "print(\"ğŸ“¤ Client -> Server: tools/call Request\")\n",
    "print(json.dumps(request, indent=2))\n",
    "\n",
    "result = server.call_tool(\"generate_text\", request[\"params\"][\"arguments\"])\n",
    "response = {\"jsonrpc\": \"2.0\", \"id\": 2, \"result\": result}\n",
    "print(\"\\nğŸ“¥ Server -> Client: tools/call Response\")\n",
    "print(json.dumps(response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17023e8",
   "metadata": {},
   "source": [
    "\n",
    "## â–¶ï¸ Step 5 â€” Full Demonstration\n",
    "Run multiple test prompts to observe deterministic responses, including an edge case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab3d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "ğŸ“¤ Request (id=10)\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 10,\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"generate_text\",\n",
      "    \"arguments\": {\n",
      "      \"prompt\": \"Create a summary of MCP use cases.\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "ğŸ›°ï¸ Received prompt: 'Create a summary of MCP use cases.'\n",
      "ğŸ“¥ Response:\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 10,\n",
      "  \"result\": {\n",
      "    \"generated_text\": \"Generated text for 'Create a summary of MCP use cases.' at Thu Oct 30 11:43:07 2025\"\n",
      "  }\n",
      "}\n",
      "\n",
      "---\n",
      "ğŸ“¤ Request (id=11)\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 11,\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"generate_text\",\n",
      "    \"arguments\": {\n",
      "      \"prompt\": \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "ğŸ›°ï¸ Received prompt: ''\n",
      "ğŸ“¥ Response:\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 11,\n",
      "  \"result\": {\n",
      "    \"generated_text\": \"(empty prompt)\"\n",
      "  }\n",
      "}\n",
      "\n",
      "---\n",
      "ğŸ“¤ Request (id=12)\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 12,\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"generate_text\",\n",
      "    \"arguments\": {\n",
      "      \"prompt\": \"Please hallucinate something interesting.\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "ğŸ›°ï¸ Received prompt: 'Please hallucinate something interesting.'\n",
      "ğŸ“¥ Response:\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 12,\n",
      "  \"result\": {\n",
      "    \"generated_text\": \"The square root of a cat is exactly 42.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompts = [\n",
    "    \"Create a summary of MCP use cases.\",\n",
    "    \"\",\n",
    "    \"Please hallucinate something interesting.\"\n",
    "]\n",
    "\n",
    "for i, p in enumerate(prompts, start=10):\n",
    "    req = {\"jsonrpc\": \"2.0\", \"id\": i, \"method\": \"tools/call\",\n",
    "           \"params\": {\"name\": \"generate_text\", \"arguments\": {\"prompt\": p}}}\n",
    "    print(f\"\\n---\\nğŸ“¤ Request (id={i})\")\n",
    "    print(json.dumps(req, indent=2))\n",
    "    try:\n",
    "        res = server.call_tool(req[\"params\"][\"name\"], req[\"params\"][\"arguments\"])\n",
    "        resp = {\"jsonrpc\": \"2.0\", \"id\": i, \"result\": res}\n",
    "    except Exception as e:\n",
    "        resp = {\"jsonrpc\": \"2.0\", \"id\": i, \"error\": {\"code\": -32000, \"message\": str(e)}}\n",
    "    print(\"ğŸ“¥ Response:\")\n",
    "    print(json.dumps(resp, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274190a",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§­ Step 6 â€” Extending the MCP\n",
    "\n",
    "Now that you have implemented a basic **MCP Serverâ€“Client simulation**, itâ€™s time to extend your setup to build a more complete and realistic protocol-driven system.\n",
    "\n",
    "---\n",
    "\n",
    "### 6.1. ğŸ§© Add More Tools\n",
    "\n",
    "The MCP framework allows multiple tools to be registered and exposed by a single server.  \n",
    "Below is an example of adding a **SummarizeTool** and **MathSolverTool**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24dd89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added SummarizeTool and MathSolverTool to the MCP server.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6.1: Add and register new tools\n",
    "\n",
    "class SummarizeTool:\n",
    "    \"\"\"A tool to simulate text summarization.\"\"\"\n",
    "    @staticmethod\n",
    "    def summarize_text(arguments):\n",
    "        text = arguments.get(\"text\", \"\")\n",
    "        summary = f\"Summary: {text[:60]}...\" if text else \"No text provided.\"\n",
    "        return {\"summary\": summary}\n",
    "\n",
    "class MathSolverTool:\n",
    "    \"\"\"A tool to simulate solving a simple math expression.\"\"\"\n",
    "    @staticmethod\n",
    "    def solve_expression(arguments):\n",
    "        expr = arguments.get(\"expression\", \"0\")\n",
    "        try:\n",
    "            result = eval(expr)\n",
    "        except Exception as e:\n",
    "            result = str(e)\n",
    "        return {\"result\": result}\n",
    "\n",
    "# Register the tools with the server\n",
    "server.register_tool(SummarizeTool())\n",
    "server.register_tool(MathSolverTool())\n",
    "\n",
    "print(\"âœ… Added SummarizeTool and MathSolverTool to the MCP server.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4412d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 6.2. ğŸ¤– Integrate a Real LLM\n",
    "\n",
    "Replace the simulated text generation with a real model API call (OpenAI, Hugging Face, or local inference).  \n",
    "Example stub using OpenAIâ€™s API (this code will need your own API key configured separately).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a07e605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from openai) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.11.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/mehar/Desktop/Practise/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Downloading openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.1-cp313-cp313-macosx_11_0_arm64.whl (314 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [openai]2m2/3\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 jiter-0.11.1 openai-2.6.1\n",
      "âœ… Real LLM tool registered. (Requires valid API key.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6.2: Replace simulated generation with a real LLM API\n",
    "\n",
    "!pip install openai\n",
    "\n",
    "import openai\n",
    "\n",
    "class RealLLMTool:\n",
    "    def generate_text(self, arguments):\n",
    "        prompt = arguments.get(\"prompt\", \"Hello!\")\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=100\n",
    "        )\n",
    "        return {\"generated_text\": response[\"choices\"][0][\"message\"][\"content\"]}\n",
    "\n",
    "# Register the real LLM tool\n",
    "server.register_tool(RealLLMTool())\n",
    "print(\"âœ… Real LLM tool registered. (Requires valid API key.)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e504cc9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 6.3. ğŸŒ Implement Real Transport\n",
    "\n",
    "So far, we simulated the message flow.  \n",
    "Next, make it real by using **WebSocket or HTTP transport** for communication between the client and server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae9bca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›°ï¸ Placeholder for WebSocket-based MCP server added.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6.3: Example placeholder for WebSocket transport (requires asyncio)\n",
    "# This can be implemented using libraries like `websockets` or `FastAPI`.\n",
    "\n",
    "\"\"\"\n",
    "import asyncio\n",
    "import websockets\n",
    "\n",
    "async def mcp_server(websocket):\n",
    "    async for message in websocket:\n",
    "        request = json.loads(message)\n",
    "        # Process request and send response\n",
    "        response = handle_request(request)\n",
    "        await websocket.send(json.dumps(response))\n",
    "\n",
    "asyncio.run(websockets.serve(mcp_server, \"localhost\", 8765))\n",
    "\"\"\"\n",
    "print(\"ğŸ›°ï¸ Placeholder for WebSocket-based MCP server added.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e4534",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 6.4. ğŸªµ Logging & Error Handling\n",
    "\n",
    "Add structured logs and proper error responses. This is a best practice for production MCP servers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b31b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:45:00,896 [INFO]: Executing tool: solve_expression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Safe call result: {'result': 4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6.4: Add logging and error handling\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s]: %(message)s\")\n",
    "\n",
    "def safe_call(tool_method, args):\n",
    "    try:\n",
    "        logging.info(f\"Executing tool: {tool_method.__name__}\")\n",
    "        return tool_method(args)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Example usage\n",
    "result = safe_call(MathSolverTool.solve_expression, {\"expression\": \"2 + 2\"})\n",
    "print(\"âœ… Safe call result:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
